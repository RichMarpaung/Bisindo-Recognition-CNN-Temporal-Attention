{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d2f2b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versi TensorFlow: 2.20.0\n",
      "Mode: CPU Only (Optimized for Stability)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "import pickle\n",
    "\n",
    "# ==========================================\n",
    "# 1. KONFIGURASI SISTEM (CPU MODE)\n",
    "# ==========================================\n",
    "# Paksa TensorFlow menggunakan CPU agar stabil di Python 3.13\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "print(f\"Versi TensorFlow: {tf.__version__}\")\n",
    "print(\"Mode: CPU Only (Optimized for Stability)\")\n",
    "\n",
    "# Path Data (Pastikan folder ini berisi file .npy hasil convert_data.py)\n",
    "DATA_DIR = r\"C:\\Users\\robot\\OneDrive\\Documents\\Rich\\processed_data_uint8\" \n",
    "\n",
    "CONFIG = {\n",
    "    \"IMG_SIZE\": 112,\n",
    "    \"MAX_FRAMES\": 20,\n",
    "    \"BATCH_SIZE\": 32,\n",
    "    \"EPOCHS\": 20,       # Bisa diturunkan ke 10-15 jika di CPU terasa lama\n",
    "    \"LEARNING_RATE\": 1e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bdaaca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. DEFINISI LAYER ATENSI (PROPOSED METHOD)\n",
    "# ==========================================\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class TemporalAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(TemporalAttention, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1), initializer=\"normal\")\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1), initializer=\"zeros\")\n",
    "        super(TemporalAttention, self).build(input_shape)\n",
    "    def call(self, x):\n",
    "        e = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b)\n",
    "        a = tf.keras.backend.softmax(e, axis=1)\n",
    "        output = x * a\n",
    "        return tf.keras.backend.sum(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e48a6040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sedang membaca struktur data...\n",
      "\n",
      "✅ Total Data: 2000\n",
      "   - Training   (70%): 1399 sampel\n",
      "   - Validation (15%): 301 sampel (Untuk Early Stopping)\n",
      "   - Testing    (15%): 300 sampel (Untuk Evaluasi Akhir Jurnal)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3. PREPARASI DATA (SPLIT 70:15:15)\n",
    "# ==========================================\n",
    "def load_dataset_info(data_path):\n",
    "    all_files = []\n",
    "    all_labels = []\n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"❌ Error: Folder {data_path} tidak ditemukan!\")\n",
    "        return [], [], []\n",
    "\n",
    "    class_names = sorted([d for d in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, d))])\n",
    "    \n",
    "    for label in class_names:\n",
    "        folder = os.path.join(data_path, label)\n",
    "        files = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.npy')]\n",
    "        for f in files:\n",
    "            all_files.append(f)\n",
    "            all_labels.append(label)\n",
    "    return all_files, all_labels, class_names\n",
    "\n",
    "print(\"Sedang membaca struktur data...\")\n",
    "files, labels, class_names = load_dataset_info(DATA_DIR)\n",
    "\n",
    "if len(files) > 0:\n",
    "    lb = LabelBinarizer()\n",
    "    y_encoded = lb.fit_transform(labels)\n",
    "    \n",
    "    # --- SPLIT TAHAP 1: Ambil Data Test (15%) ---\n",
    "    # Data ini benar-benar \"Ghaib\" (Unseen) saat training\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        files, y_encoded, test_size=0.15, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "    \n",
    "    # --- SPLIT TAHAP 2: Pecah Sisanya jadi Train (70%) & Validation (15%) ---\n",
    "    # Sisa 85% dibagi lagi. 0.15 / 0.85 = ~0.1765\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.1765, random_state=42, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✅ Total Data: {len(files)}\")\n",
    "    print(f\"   - Training   (70%): {len(X_train)} sampel\")\n",
    "    print(f\"   - Validation (15%): {len(X_val)} sampel (Untuk Early Stopping)\")\n",
    "    print(f\"   - Testing    (15%): {len(X_test)} sampel (Untuk Evaluasi Akhir Jurnal)\")\n",
    "\n",
    "    # --- PIPELINE DATA ---\n",
    "    def load_npy_wrapper(file_path, label):\n",
    "        def _load_numpy(fp):\n",
    "            return np.load(fp.decode())\n",
    "        video = tf.numpy_function(_load_numpy, [file_path], tf.uint8)\n",
    "        video.set_shape([CONFIG[\"MAX_FRAMES\"], CONFIG[\"IMG_SIZE\"], CONFIG[\"IMG_SIZE\"], 3])\n",
    "        video = tf.cast(video, tf.float32) / 255.0\n",
    "        return video, label\n",
    "\n",
    "    def create_dataset(paths, labels, is_train=True):\n",
    "        ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "        if is_train:\n",
    "            ds = ds.shuffle(1000)\n",
    "        ds = ds.map(load_npy_wrapper, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        ds = ds.batch(CONFIG[\"BATCH_SIZE\"])\n",
    "        ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "        return ds\n",
    "\n",
    "    train_ds = create_dataset(X_train, y_train, is_train=True)\n",
    "    val_ds = create_dataset(X_val, y_val, is_train=False)\n",
    "    test_ds = create_dataset(X_test, y_test, is_train=False) # Data Uji Akhir\n",
    "\n",
    "else:\n",
    "    print(\"⚠️ Data kosong! Jalankan convert_data.py dulu.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f21e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- MULAI PROSES TRAINING ---\n",
      "\n",
      "========================================\n",
      "TRAINING MODEL: STATIC\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robot\\AppData\\Local\\Temp\\ipykernel_21596\\3604349938.py:6: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base = tf.keras.applications.MobileNetV2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 3s/step - accuracy: 0.0586 - loss: 3.9099 - val_accuracy: 0.1661 - val_loss: 3.3585 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 3s/step - accuracy: 0.1580 - loss: 3.2679 - val_accuracy: 0.3223 - val_loss: 3.0191 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 3s/step - accuracy: 0.2259 - loss: 3.0155 - val_accuracy: 0.4618 - val_loss: 2.7387 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 3s/step - accuracy: 0.3109 - loss: 2.7616 - val_accuracy: 0.5116 - val_loss: 2.4959 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m22/44\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 0.3446 - loss: 2.6121"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 4. BUILD & TRAINING MODEL\n",
    "# ==========================================\n",
    "def build_model(model_type, num_classes):\n",
    "    # Backbone: MobileNetV2\n",
    "    base = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=(CONFIG[\"IMG_SIZE\"], CONFIG[\"IMG_SIZE\"], 3),\n",
    "        include_top=False, \n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base.trainable = False # CPU optimization: Bekukan backbone\n",
    "    \n",
    "    cnn_extractor = tf.keras.Model(inputs=base.input, outputs=tf.keras.layers.GlobalAveragePooling2D()(base.output))\n",
    "\n",
    "    # Sequence Input\n",
    "    inputs = tf.keras.layers.Input(shape=(CONFIG[\"MAX_FRAMES\"], CONFIG[\"IMG_SIZE\"], CONFIG[\"IMG_SIZE\"], 3))\n",
    "    x = tf.keras.layers.TimeDistributed(cnn_extractor)(inputs)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    # Cabang Arsitektur\n",
    "    if model_type == 'static':\n",
    "        x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    elif model_type == 'lstm':\n",
    "        x = tf.keras.layers.LSTM(128)(x)\n",
    "    elif model_type == 'attention':\n",
    "        x = TemporalAttention()(x)\n",
    "\n",
    "    # Classifier\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs, outputs, name=model_type)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=CONFIG[\"LEARNING_RATE\"]),\n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Loop Training 3 Model\n",
    "history_dict = {}\n",
    "models_list = ['static', 'lstm', 'attention']\n",
    "\n",
    "print(\"\\n--- MULAI PROSES TRAINING ---\")\n",
    "\n",
    "for m_type in models_list:\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"TRAINING MODEL: {m_type.upper()}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    model = build_model(m_type, len(class_names))\n",
    "    \n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds, # Pakai Validation Set (bukan Test Set)\n",
    "        epochs=CONFIG[\"EPOCHS\"],\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    history_dict[m_type] = history.history\n",
    "    model.save(f\"bisindo_model_{m_type}.keras\")\n",
    "\n",
    "print(\"\\n✅ Semua model selesai dilatih dan disimpan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf73032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 5. VISUALISASI GRAFIK TRAINING\n",
    "# ==========================================\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "fig.suptitle('Dinamika Training: Akurasi & Loss', fontsize=16)\n",
    "\n",
    "for idx, m_type in enumerate(models_list):\n",
    "    hist = history_dict[m_type]\n",
    "    epochs = range(1, len(hist['accuracy']) + 1)\n",
    "    \n",
    "    # Plot Accuracy\n",
    "    axes[idx, 0].plot(epochs, hist['accuracy'], 'b-', label='Train Acc')\n",
    "    axes[idx, 0].plot(epochs, hist['val_accuracy'], 'r--', label='Val Acc')\n",
    "    axes[idx, 0].set_title(f'{m_type.upper()} - Accuracy')\n",
    "    axes[idx, 0].legend()\n",
    "    axes[idx, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot Loss\n",
    "    axes[idx, 1].plot(epochs, hist['loss'], 'b-', label='Train Loss')\n",
    "    axes[idx, 1].plot(epochs, hist['val_loss'], 'r--', label='Val Loss')\n",
    "    axes[idx, 1].set_title(f'{m_type.upper()} - Loss')\n",
    "    axes[idx, 1].legend()\n",
    "    axes[idx, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817ed3d0",
   "metadata": {},
   "source": [
    "Usulan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1063b32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==========================================\n",
    "# VISUALISASI KHUSUS MODEL USULAN\n",
    "# ==========================================\n",
    "\n",
    "# Ambil data dari history\n",
    "# (Pastikan variabel 'history' sudah ada dari proses training sebelumnya)\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Buat Canvas (1 Baris, 2 Kolom)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.suptitle('Evaluasi Training: MobileNetV2 + Temporal Attention', fontsize=14, fontweight='bold')\n",
    "\n",
    "# --- Plot 1: Akurasi ---\n",
    "axes[0].plot(epochs, acc, 'b-o', linewidth=2, label='Training Acc')\n",
    "axes[0].plot(epochs, val_acc, 'r--s', linewidth=2, label='Validation Acc')\n",
    "axes[0].set_title('Grafik Akurasi (Accuracy)')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Akurasi')\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# --- Plot 2: Loss ---\n",
    "axes[1].plot(epochs, loss, 'b-o', linewidth=2, label='Training Loss')\n",
    "axes[1].plot(epochs, val_loss, 'r--s', linewidth=2, label='Validation Loss')\n",
    "axes[1].set_title('Grafik Error (Loss)')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend(loc='upper right')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Simpan gambar agar bisa ditaruh di jurnal/skripsi\n",
    "plt.savefig('grafik_training_proposed.png', dpi=300) \n",
    "print(\"✅ Grafik berhasil disimpan sebagai 'grafik_training_proposed.png'\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1c83bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 6. EVALUASI TEST SET (SINTA 2 STANDARDS)\n",
    "# ==========================================\n",
    "print(\"\\n--- EVALUASI PADA DATA TEST (UNSEEN DATA) ---\")\n",
    "\n",
    "summary_metrics = []\n",
    "y_true = np.argmax(y_test, axis=1) # Label asli data test\n",
    "auc_scores = []\n",
    "\n",
    "# Setup Plot ROC\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['grey', 'blue', 'green']\n",
    "styles = ['--', '--', '-']\n",
    "\n",
    "for m_type, color, style in zip(models_list, colors, styles):\n",
    "    path_model = f\"bisindo_model_{m_type}.keras\"\n",
    "    if not os.path.exists(path_model): continue\n",
    "        \n",
    "    print(f\"Menguji Model: {m_type.upper()}...\")\n",
    "    model = tf.keras.models.load_model(path_model, custom_objects={'TemporalAttention': TemporalAttention})\n",
    "    \n",
    "    # Prediksi\n",
    "    y_pred_probs = model.predict(test_ds, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    \n",
    "    # 1. Metrik Dasar\n",
    "    acc = np.mean(y_pred == y_true)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    summary_metrics.append({'Model': m_type.upper(), 'Accuracy': acc, 'Precision': prec, 'Recall': rec, 'F1-Score': f1})\n",
    "    \n",
    "    # 2. ROC & AUC (Micro-Average)\n",
    "    fpr, tpr, _ = roc_curve(y_test.ravel(), y_pred_probs.ravel())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    auc_scores.append({'Model': m_type.upper(), 'AUC': roc_auc})\n",
    "    \n",
    "    plt.plot(fpr, tpr, color=color, linestyle=style, lw=2, label=f'{m_type.upper()} (AUC={roc_auc:.4f})')\n",
    "    \n",
    "    # 3. Confusion Matrix (Hanya Proposed Method)\n",
    "    if m_type == 'attention':\n",
    "        cm_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Finalisasi Plot ROC\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "plt.title('Kurva ROC Perbandingan Model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Tampilkan Tabel\n",
    "df_metrics = pd.DataFrame(summary_metrics)\n",
    "print(\"\\n=== TABEL PERFORMA (METRIK UTAMA) ===\")\n",
    "print(df_metrics.round(4).to_string(index=False))\n",
    "\n",
    "# Plot Confusion Matrix (Proposed)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_matrix, annot=False, cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix: Proposed Method (Attention)')\n",
    "plt.xlabel('Prediksi'); plt.ylabel('Aktual')\n",
    "plt.show()\n",
    "\n",
    "# Simpan semua hasil\n",
    "df_metrics.to_csv('hasil_skripsi_final.csv', index=False)\n",
    "print(\"✅ Selesai! Data tersimpan di 'hasil_skripsi_final.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
